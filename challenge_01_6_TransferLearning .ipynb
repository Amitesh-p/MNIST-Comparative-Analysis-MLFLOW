{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning :\n",
    "\n",
    "# Prediction of Even/odd number from the MINIST Handwritten dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lenovo\\.conda\\envs\\$PYTHON36_ENV_NAME\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#tf.random.set_seed(42)\n",
    "#np.random.seed(42)\n",
    "\n",
    "LAYERS = [ tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")]\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"SGD\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 10s 177us/sample - loss: 0.5574 - acc: 0.8498 - val_loss: 0.3114 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 9s 166us/sample - loss: 0.2960 - acc: 0.9158 - val_loss: 0.2565 - val_acc: 0.9267\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 9s 162us/sample - loss: 0.2521 - acc: 0.9284 - val_loss: 0.2312 - val_acc: 0.9344\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 9s 159us/sample - loss: 0.2224 - acc: 0.9376 - val_loss: 0.2076 - val_acc: 0.9403\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 9s 162us/sample - loss: 0.1996 - acc: 0.9435 - val_loss: 0.1900 - val_acc: 0.9460\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.1809 - acc: 0.9484 - val_loss: 0.1746 - val_acc: 0.9487\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 10s 175us/sample - loss: 0.1652 - acc: 0.9533 - val_loss: 0.1610 - val_acc: 0.9525\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 9s 170us/sample - loss: 0.1516 - acc: 0.9568 - val_loss: 0.1498 - val_acc: 0.9561\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 9s 170us/sample - loss: 0.1401 - acc: 0.9607 - val_loss: 0.1409 - val_acc: 0.9576\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 10s 173us/sample - loss: 0.1300 - acc: 0.9631 - val_loss: 0.1331 - val_acc: 0.9589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c08333c160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 10, validation_data = (X_test, y_test))\n",
    "#history = model.fit(X_train, Y_train, validation_data=VALIDATION_SET, batch_size=200, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"pretrained_mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_mnist_data = tf.keras.models.load_model(\"pretrained_mnist_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_mnist_data.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a new model ( Transfer learning)\n",
    "with lower layers from the past model and changing the output layer to binary classification with sigmoid as an activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_pretrained_layer = pretrained_mnist_data.layers[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.Sequential(lower_pretrained_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lenovo\\.conda\\envs\\$PYTHON36_ENV_NAME\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "new_model.compile(loss = \"binary_crossentropy\", \n",
    "                  optimizer = \"SGD\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 265,701\n",
      "Trainable params: 265,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(y_train%2 == 0, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_even_odd_labels(labels):\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels[idx] = np.where(label % 2 == 0, 1, 0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin, y_test_bin, y_valid_bin = update_even_odd_labels([y_train, y_test, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_valid_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 - 16s - loss: 0.1944 - acc: 0.9267 - val_loss: 0.1199 - val_acc: 0.9610\n",
      "Epoch 2/10\n",
      "55000/55000 - 14s - loss: 0.1077 - acc: 0.9632 - val_loss: 0.0891 - val_acc: 0.9704\n",
      "Epoch 3/10\n",
      "55000/55000 - 15s - loss: 0.0871 - acc: 0.9705 - val_loss: 0.0777 - val_acc: 0.9724\n",
      "Epoch 4/10\n",
      "55000/55000 - 19s - loss: 0.0758 - acc: 0.9740 - val_loss: 0.0680 - val_acc: 0.9776\n",
      "Epoch 5/10\n",
      "55000/55000 - 14s - loss: 0.0680 - acc: 0.9777 - val_loss: 0.0624 - val_acc: 0.9794\n",
      "Epoch 6/10\n",
      "55000/55000 - 14s - loss: 0.0627 - acc: 0.9784 - val_loss: 0.0612 - val_acc: 0.9792\n",
      "Epoch 7/10\n",
      "55000/55000 - 15s - loss: 0.0575 - acc: 0.9806 - val_loss: 0.0569 - val_acc: 0.9816\n",
      "Epoch 8/10\n",
      "55000/55000 - 18s - loss: 0.0534 - acc: 0.9817 - val_loss: 0.0550 - val_acc: 0.9818\n",
      "Epoch 9/10\n",
      "55000/55000 - 14s - loss: 0.0499 - acc: 0.9831 - val_loss: 0.0527 - val_acc: 0.9820\n",
      "Epoch 10/10\n",
      "55000/55000 - 10s - loss: 0.0469 - acc: 0.9848 - val_loss: 0.0582 - val_acc: 0.9794\n"
     ]
    }
   ],
   "source": [
    "history = new_model.fit(X_train, y_train_bin, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid_bin), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 194us/sample - loss: 0.0582 - acc: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.058186717158928515, 0.9785]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(X_test, y_test_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 2, 1, 0], dtype=uint8), array([0, 1, 0, 1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:4]\n",
    "\n",
    "y_test[:4], y_test_bin[:4]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(new_model.predict(X_new), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
