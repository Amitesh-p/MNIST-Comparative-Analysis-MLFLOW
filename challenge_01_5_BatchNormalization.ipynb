{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - 01: (Document 5)\n",
    "\n",
    "# Introduction to the concept of Batch Normalization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lenovo\\.conda\\envs\\$PYTHON36_ENV_NAME\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "LAYERS = [ tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")]\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"SGD\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 13s 242us/sample - loss: 0.5657 - acc: 0.8482 - val_loss: 0.3220 - val_acc: 0.9101\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 11s 196us/sample - loss: 0.3049 - acc: 0.9129 - val_loss: 0.2678 - val_acc: 0.9247\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 10s 190us/sample - loss: 0.2603 - acc: 0.9255 - val_loss: 0.2445 - val_acc: 0.9311\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.2301 - acc: 0.9343 - val_loss: 0.2210 - val_acc: 0.9369\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 11s 197us/sample - loss: 0.2057 - acc: 0.9414 - val_loss: 0.1977 - val_acc: 0.9419\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 11s 203us/sample - loss: 0.1866 - acc: 0.9465 - val_loss: 0.1811 - val_acc: 0.9467\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 12s 220us/sample - loss: 0.1703 - acc: 0.9520 - val_loss: 0.1654 - val_acc: 0.9531\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 13s 237us/sample - loss: 0.1564 - acc: 0.9555 - val_loss: 0.1591 - val_acc: 0.9545\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 12s 216us/sample - loss: 0.1445 - acc: 0.9590 - val_loss: 0.1484 - val_acc: 0.9558\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 12s 225us/sample - loss: 0.1341 - acc: 0.9614 - val_loss: 0.1409 - val_acc: 0.9599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cdb37cb4e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 10, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization Approach 1 \n",
    "\n",
    "In this approach , we add BN after each layer after the activation function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS = [ tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")]\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784*4 #4 indicating 4 parameters mean,variance, gamma, beta \n",
    "# where non trainable parameters are means, variance\n",
    "# where trainable parameters are gamma , beta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 *4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x1cdbea0a128>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x1cdbea0a278>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1cdbea0a588>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x1cdbea0a828>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1cdbea0ab38>,\n",
       " <tensorflow.python.keras.layers.normalization.BatchNormalization at 0x1cdbea0add8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1cdbea1a128>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'batch_normalization/gamma:0' shape=(784,) dtype=float32>,\n",
       " <tf.Variable 'batch_normalization/beta:0' shape=(784,) dtype=float32>,\n",
       " <tf.Variable 'batch_normalization/moving_mean:0' shape=(784,) dtype=float32>,\n",
       " <tf.Variable 'batch_normalization/moving_variance:0' shape=(784,) dtype=float32>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization/gamma:0 True\n",
      "batch_normalization/beta:0 True\n",
      "batch_normalization/moving_mean:0 False\n",
      "batch_normalization/moving_variance:0 False\n"
     ]
    }
   ],
   "source": [
    "for variable in bn1.variables:\n",
    "    print(variable.name, variable.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"SGD\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 20s 371us/sample - loss: 0.4602 - acc: 0.8645 - val_loss: 0.3285 - val_acc: 0.9062\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 18s 328us/sample - loss: 0.3493 - acc: 0.9003 - val_loss: 0.3115 - val_acc: 0.9135\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 20s 357us/sample - loss: 0.3338 - acc: 0.9042 - val_loss: 0.3077 - val_acc: 0.9177\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 18s 330us/sample - loss: 0.3223 - acc: 0.9076 - val_loss: 0.3034 - val_acc: 0.9182\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 20s 359us/sample - loss: 0.3172 - acc: 0.9091 - val_loss: 0.3029 - val_acc: 0.9172\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 18s 335us/sample - loss: 0.3110 - acc: 0.9108 - val_loss: 0.2985 - val_acc: 0.9198\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 19s 342us/sample - loss: 0.3024 - acc: 0.9127 - val_loss: 0.2989 - val_acc: 0.9196\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 22s 393us/sample - loss: 0.3022 - acc: 0.9121 - val_loss: 0.3008 - val_acc: 0.9199\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 18s 318us/sample - loss: 0.2977 - acc: 0.9150 - val_loss: 0.3017 - val_acc: 0.9191\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 19s 340us/sample - loss: 0.2934 - acc: 0.9164 - val_loss: 0.2976 - val_acc: 0.9197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cddeb84e10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 10, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization Approach 2 \n",
    "\n",
    "In this appraoch, we are adding Normalization techniques after each layer before the activation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS_BN_BIAS_FALSE = [\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(300, use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.Dense(100, use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "]\n",
    "\n",
    "model = tf.keras.models.Sequential(LAYERS_BN_BIAS_FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               235200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               30000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 270,946\n",
      "Trainable params: 268,578\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"SGD\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 24s 428us/sample - loss: 0.4504 - acc: 0.8759 - val_loss: 0.2156 - val_acc: 0.9400\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 19s 347us/sample - loss: 0.2219 - acc: 0.9371 - val_loss: 0.1617 - val_acc: 0.9521\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 21s 380us/sample - loss: 0.1708 - acc: 0.9520 - val_loss: 0.1356 - val_acc: 0.9603\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 20s 356us/sample - loss: 0.1399 - acc: 0.9601 - val_loss: 0.1248 - val_acc: 0.9640\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 17s 309us/sample - loss: 0.1186 - acc: 0.9653 - val_loss: 0.1147 - val_acc: 0.9676\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 17s 311us/sample - loss: 0.1037 - acc: 0.9702 - val_loss: 0.1101 - val_acc: 0.9683\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 20s 357us/sample - loss: 0.0888 - acc: 0.9747 - val_loss: 0.1039 - val_acc: 0.9702\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 20s 363us/sample - loss: 0.0799 - acc: 0.9763 - val_loss: 0.1032 - val_acc: 0.9707\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 18s 333us/sample - loss: 0.0710 - acc: 0.9793 - val_loss: 0.1002 - val_acc: 0.9727\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 19s 339us/sample - loss: 0.0634 - acc: 0.9821 - val_loss: 0.0971 - val_acc: 0.9731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cdf20a4978>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 10, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations \n",
    "\n",
    "1. gamma and beta -> get new trainable parameters \n",
    "2. mean and standard deviation --> non trainable parameters \n",
    "3. that means cost functions depends on 4 parameters, mean, SD, gamma, beta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantages \n",
    "\n",
    "1. You wont need scaling of data if we are using BN as a first layer\n",
    "2. Although it adds two extra learnable parameters, still it converges faster , thus getting better results \n",
    "3. It helps to reduce your Gradient vanishing and exploading problem \n",
    "4. It does not get effected by choice of activation function and weight intialization \n",
    "5. It solves the problem of Internal Covariate shift "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disadvantages \n",
    "\n",
    "1. It incrases the complexity of network \n",
    "2. No of learnable paramters increased \n",
    "3. complexity -> runtime penalty hence prediction is slow but more accurate \n",
    "4. Training time increased but convergence is faster "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When to use \n",
    "\n",
    "1. for deep neural Network layers more than 10\n",
    "2. Mostly used in CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
